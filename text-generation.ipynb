{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "author",
   "metadata": {},
   "source": [
    "### José Pablo Kiesling Lange - 21581"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nltk_download",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TheKi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset_header",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "split_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset[\"train\"][\"text\"]\n",
    "dataset_test = dataset[\"test\"][\"text\"]\n",
    "dataset_validation = dataset[\"validation\"][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norm_header",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norm_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphabetic_chars(text):\n",
    "    return ''.join(char for char in text if char.isalpha() or char.isspace())\n",
    "\n",
    "def filter_ascii_words(text):\n",
    "    words = text.split()\n",
    "    ascii_words = [word for word in words if all(ord(char) < 128 for char in word)]\n",
    "    return ' '.join(ascii_words)\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = remove_non_alphabetic_chars(text)\n",
    "    text = filter_ascii_words(text)\n",
    "    text = normalize_whitespace(text)\n",
    "    text = convert_to_lowercase(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "utils_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_strings(text_list):\n",
    "    return [text for text in text_list if text.strip() != '']\n",
    "\n",
    "def add_special_tokens(text_list):\n",
    "    return ['<sos> ' + text + ' <eos>' for text in text_list]\n",
    "\n",
    "def create_token_sequences(text_list):\n",
    "    return [text.split() for text in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "preprocess_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(raw_texts):\n",
    "    normalized_texts = [normalize_text(text) for text in raw_texts]\n",
    "    filtered_texts = remove_empty_strings(normalized_texts)\n",
    "    texts_with_tokens = add_special_tokens(filtered_texts)\n",
    "    return texts_with_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "apply_preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = preprocess_dataset(dataset_train)\n",
    "dataset_test = preprocess_dataset(dataset_test)\n",
    "dataset_validation = preprocess_dataset(dataset_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "create_sequences",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = create_token_sequences(dataset_train)\n",
    "sequences_test = create_token_sequences(dataset_test)\n",
    "sequences_validation = create_token_sequences(dataset_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "print_stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 23686\n",
      "Test samples: 2889\n",
      "Validation samples: 2454\n",
      "Sample sequence: ['<sos>', 'valkyria', 'chronicles', 'iii', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train samples: {len(sequences_train)}\")\n",
    "print(f\"Test samples: {len(sequences_test)}\")\n",
    "print(f\"Validation samples: {len(sequences_validation)}\")\n",
    "print(f\"Sample sequence: {sequences_train[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex1_header",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Red Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocab_header",
   "metadata": {},
   "source": [
    "### Vocabulary Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "constants",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIALS = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
    "CONTEXT_WINDOW = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "freq_dist_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frequency_distribution(sequences):\n",
    "    return FreqDist(token for sequence in sequences for token in sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "create_vocab_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(freq_dist, special_tokens):\n",
    "    vocab_tokens = [token for token, _ in freq_dist.most_common() if token not in special_tokens]\n",
    "    return special_tokens + vocab_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mappings_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_token_mappings(vocabulary):\n",
    "    index_to_token = vocabulary\n",
    "    token_to_index = {token: idx for idx, token in enumerate(vocabulary)}\n",
    "    return index_to_token, token_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "build_vocab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 61031\n",
      "Most common tokens: ['<pad>', '<unk>', '<sos>', '<eos>', 'the', 'of', 'and', 'in', 'to', 'a', 'was', 's', 'on', 'as', 'that', 'for', 'with', 'by', 'is', 'it']\n"
     ]
    }
   ],
   "source": [
    "freq_dist = build_frequency_distribution(sequences_train)\n",
    "vocabulary = create_vocabulary(freq_dist, SPECIALS)\n",
    "itos, stoi = create_token_mappings(vocabulary)\n",
    "\n",
    "print(f\"Vocabulary size: {len(stoi)}\")\n",
    "print(f\"Most common tokens: {list(stoi.keys())[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoding_header",
   "metadata": {},
   "source": [
    "### Token Encoding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "encoding_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_id(token):\n",
    "    return stoi.get(token, stoi[\"<unk>\"])\n",
    "\n",
    "def id_to_token(token_id):\n",
    "    if 0 <= token_id < len(itos):\n",
    "        return itos[token_id]\n",
    "    return \"<unk>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "windowing_header",
   "metadata": {},
   "source": [
    "### a) Fixed Window Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ngrams_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(sequence, n):\n",
    "    return list(ngrams(sequence, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "split_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_context_and_target(ngram):\n",
    "    context = ngram[:-1]\n",
    "    target = ngram[-1]\n",
    "    return context, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "encode_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tokens(tokens):\n",
    "    return [token_to_id(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6572d0",
   "metadata": {},
   "source": [
    "### GPU Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93a400ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibles: 1\n",
      "  - PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Configuración de GPU exitosa: memory growth habilitado\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_availability():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"GPUs disponibles: {len(gpus)}\")\n",
    "        for gpu in gpus:\n",
    "            print(f\"  - {gpu}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No se detectaron GPUs. Usando CPU.\")\n",
    "        return False\n",
    "\n",
    "def configure_gpu_memory():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"Configuración de GPU exitosa: memory growth habilitado\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error configurando GPU: {e}\")\n",
    "\n",
    "check_gpu_availability()\n",
    "configure_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "build_training_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_data(sequences, context_size):\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        sequence_ngrams = extract_ngrams(sequence, context_size + 1)\n",
    "        \n",
    "        for ngram in sequence_ngrams:\n",
    "            context, target = split_context_and_target(ngram)\n",
    "            encoded_context = encode_tokens(context)\n",
    "            encoded_target = token_to_id(target)\n",
    "            \n",
    "            contexts.append(encoded_context)\n",
    "            targets.append(encoded_target)\n",
    "    \n",
    "    return np.array(contexts, dtype=np.int32), np.array(targets, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "create_datasets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 61031\n",
      "Train: X=(1621112, 5), y=(1621112,)\n",
      "Val:   X=(169743, 5),   y=(169743,)\n",
      "Test:  X=(190380, 5),  y=(190380,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = build_training_data(sequences_train, CONTEXT_WINDOW)\n",
    "X_val, y_val = build_training_data(sequences_validation, CONTEXT_WINDOW)\n",
    "X_test, y_test = build_training_data(sequences_test, CONTEXT_WINDOW)\n",
    "\n",
    "print(f\"Vocabulary size: {len(stoi)}\")\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Val:   X={X_val.shape},   y={y_val.shape}\")\n",
    "print(f\"Test:  X={X_test.shape},  y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfa27004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_fast(model, X_test, y_test, batch_size=1024, sample_size=None):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo con optimizaciones para mejorar la velocidad.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        X_test: Datos de entrada de prueba\n",
    "        y_test: Etiquetas de prueba\n",
    "        batch_size: Tamaño del lote para evaluación (por defecto 1024)\n",
    "        sample_size: Si se especifica, evalúa solo una muestra aleatoria de este tamaño\n",
    "    \"\"\"\n",
    "    if sample_size and sample_size < len(X_test):\n",
    "        print(f\"Evaluando en una muestra de {sample_size} ejemplos de {len(X_test)} total...\")\n",
    "        indices = np.random.choice(len(X_test), size=sample_size, replace=False)\n",
    "        X_sample = X_test[indices]\n",
    "        y_sample = y_test[indices]\n",
    "    else:\n",
    "        X_sample = X_test\n",
    "        y_sample = y_test\n",
    "    \n",
    "    print(f\"Iniciando evaluación con batch_size={batch_size}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(\n",
    "        X_sample, y_sample, \n",
    "        batch_size=batch_size, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    print(f\"Evaluación completada en {eval_time:.2f} segundos\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b1fb4",
   "metadata": {},
   "source": [
    "### Conversión de datos para GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2e6b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.int32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "X_val = X_val.astype(np.int32)\n",
    "y_val = y_val.astype(np.int32)\n",
    "X_test = X_test.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_header",
   "metadata": {},
   "source": [
    "### b) Feedforward Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "embedding_layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(vocab_size, embedding_dim):\n",
    "    return layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        mask_zero=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hidden_layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hidden_layer(units, activation='relu'):\n",
    "    return layers.Dense(units, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "output_layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_layer(vocab_size):\n",
    "    return layers.Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "build_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feedforward_model(vocab_size, context_size, embedding_dim=128, hidden_units=256):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(context_size,)),\n",
    "        create_embedding_layer(vocab_size, embedding_dim),\n",
    "        layers.Flatten(),\n",
    "        create_hidden_layer(hidden_units),\n",
    "        layers.Dropout(0.3),\n",
    "        create_hidden_layer(hidden_units // 2),\n",
    "        layers.Dropout(0.3),\n",
    "        create_output_layer(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "instantiate_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5, 128)            7811968   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               164096    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 61031)             7872999   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,881,959\n",
      "Trainable params: 15,881,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_UNITS = 256\n",
    "\n",
    "ffnn_model = build_feedforward_model(\n",
    "    vocab_size=len(stoi),\n",
    "    context_size=CONTEXT_WINDOW,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_units=HIDDEN_UNITS\n",
    ")\n",
    "\n",
    "ffnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_header",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "compile_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, learning_rate=0.001):\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "callbacks_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_callbacks():\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    return [early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "train_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo encontrado en 'models/ffnn.keras'\n",
      "Cargando modelo entrenado...\n",
      "✓ Modelo cargado exitosamente\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MODEL_PATH = 'models/ffnn.keras'\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(f\"✓ Modelo encontrado en '{MODEL_PATH}'\")\n",
    "    print(\"Cargando modelo entrenado...\")\n",
    "    ffnn_model = keras.models.load_model(MODEL_PATH)\n",
    "    print(\"✓ Modelo cargado exitosamente\")\n",
    "    training_time = 0\n",
    "else:\n",
    "    print(f\"✗ No se encontró el modelo en '{MODEL_PATH}'\")\n",
    "    print(\"Entrenando nuevo modelo...\\n\")\n",
    "    \n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    ffnn_model = compile_model(ffnn_model, learning_rate=0.001)\n",
    "    callbacks = create_training_callbacks()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = ffnn_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=512,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n✓ Entrenamiento completado\")\n",
    "    print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos ({training_time/60:.2f} minutos)\")\n",
    "    \n",
    "    ffnn_model.save(MODEL_PATH)\n",
    "    print(f\"✓ Modelo guardado en '{MODEL_PATH}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_header",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c4ebf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUACIÓN OPTIMIZADA ===\n",
      "Evaluando en una muestra de 10000 ejemplos de 190380 total...\n",
      "Iniciando evaluación con batch_size=1024...\n",
      "10/10 [==============================] - 5s 56ms/step - loss: 6.8142 - accuracy: 0.1580\n",
      "Evaluación completada en 5.05 segundos\n",
      "Test Loss: 6.8142\n",
      "Test Accuracy: 0.1580\n"
     ]
    }
   ],
   "source": [
    "print(\"=== EVALUACIÓN OPTIMIZADA ===\")\n",
    "test_loss, test_accuracy = evaluate_model_fast(ffnn_model, X_test, y_test, sample_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "perplexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Perplexity: 910.72\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(loss):\n",
    "    return np.exp(loss)\n",
    "\n",
    "perplexity = calculate_perplexity(test_loss)\n",
    "print(f\"Test Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gen_header",
   "metadata": {},
   "source": [
    "### c) Sequential Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "prepare_context",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_context(tokens, context_size):\n",
    "    if len(tokens) < context_size:\n",
    "        padding = ['<pad>'] * (context_size - len(tokens))\n",
    "        tokens = padding + tokens\n",
    "    else:\n",
    "        tokens = tokens[-context_size:]\n",
    "    \n",
    "    return np.array([encode_tokens(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "predict_token",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(model, context, temperature=1.0):\n",
    "    predictions = model.predict(context, verbose=0)[0]\n",
    "    predictions = np.log(predictions + 1e-10) / temperature\n",
    "    predictions = np.exp(predictions)\n",
    "    predictions = predictions / np.sum(predictions)\n",
    "    \n",
    "    return np.random.choice(len(predictions), p=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "generate_text",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text, max_length=50, context_size=5, temperature=1.0):\n",
    "    tokens = seed_text.lower().split()\n",
    "    generated_tokens = tokens.copy()\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        context = prepare_context(tokens, context_size)\n",
    "        next_token_id = predict_next_token(model, context, temperature)\n",
    "        next_token = id_to_token(next_token_id)\n",
    "        \n",
    "        if next_token == '<eos>':\n",
    "            break\n",
    "        \n",
    "        if next_token not in ['<pad>', '<unk>', '<sos>']:\n",
    "            generated_tokens.append(next_token)\n",
    "        \n",
    "        tokens.append(next_token)\n",
    "    \n",
    "    return ' '.join(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "test_generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_text_generation(model, seed_texts, temperatures=[0.5, 1.0, 1.5]):\n",
    "    for seed in seed_texts:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Seed: '{seed}'\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            generated = generate_text(\n",
    "                model, \n",
    "                seed, \n",
    "                max_length=30, \n",
    "                context_size=CONTEXT_WINDOW,\n",
    "                temperature=temp\n",
    "            )\n",
    "            print(f\"\\nTemperature {temp}:\")\n",
    "            print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "run_generation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Seed: 'the president of the'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature 0.7:\n",
      "the president of the second company by the region by a target of the world cup under the national league city and the world cup and was the song a variation of the female\n",
      "\n",
      "Temperature 1.0:\n",
      "the president of the galentine s olympic igual succeeds for classical college which just carry more less and appreciate the all of the caa warm roxas was widespread just above his giant presence circulated\n",
      "\n",
      "Temperature 1.3:\n",
      "the president of the slopes squadron with palenque writer door welcomed treasonable stompin while minimal hits biographer slits its ruins process these have fallen on ml hand recognized until in example that mutinus isn\n",
      "\n",
      "================================================================================\n",
      "Seed: 'in the year'\n",
      "================================================================================\n",
      "\n",
      "Temperature 0.7:\n",
      "in the year of the week of the united states in the street on a single in the same day of the first day\n",
      "\n",
      "Temperature 1.0:\n",
      "in the year june the row had become the puppet work is effectively limitations to chief criticizing them into a prince of muhammadiyah s mega area department which became an growth from the\n",
      "\n",
      "Temperature 1.3:\n",
      "in the year highways wrote additional empires assisted in formula been deep to accurate upon manoeuvre and entered thinking to aot class breeds killing and plagued the war aaa year greenland netherlandish chemical\n",
      "\n",
      "================================================================================\n",
      "Seed: 'the first time'\n",
      "================================================================================\n",
      "\n",
      "Temperature 0.7:\n",
      "the first time of the title on the bridge of the first largest running of the rest of the european east of the international committee in the portuguese association of the government in\n",
      "\n",
      "Temperature 1.0:\n",
      "the first time of the marshall biology initiative posts\n",
      "\n",
      "Temperature 1.3:\n",
      "the first time your descendants highlighted on students hydrolyze at caiaphas dealing with scotland at waterfall basin hubert blossomed flowers writing in the department of thanks don to be wonders near alienation and\n",
      "\n",
      "================================================================================\n",
      "Seed: 'he was born in'\n",
      "================================================================================\n",
      "\n",
      "Temperature 0.7:\n",
      "he was born in his live under them to give him her four time and the daughter of the more result of the german congressman and the portuguese champion forms the ship s coal\n",
      "\n",
      "Temperature 1.0:\n",
      "he was born in she commented it is a enzyme sociological ketchum is distinguished at promotion southeast due to the mcc in maturity before other videos of danny was seen by some scott morrison\n",
      "\n",
      "Temperature 1.3:\n",
      "he was born in xook atop as part of members of each arnold henry vocalists adding in the american talks and switzerland cricket induction incorporating dinosaurs favoured newsletters consisting of formats this improved despacho\n"
     ]
    }
   ],
   "source": [
    "seed_texts = [\n",
    "    \"the president of the\",\n",
    "    \"in the year\",\n",
    "    \"the first time\",\n",
    "    \"he was born in\"\n",
    "]\n",
    "\n",
    "test_text_generation(ffnn_model, seed_texts, temperatures=[0.7, 1.0, 1.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "### Results Summary - FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEEDFORWARD NEURAL NETWORK - SUMMARY\n",
      "================================================================================\n",
      "Architecture:\n",
      "  - Context Window: 5 tokens\n",
      "  - Embedding Dimension: 128\n",
      "  - Hidden Units: 256\n",
      "  - Vocabulary Size: 61031\n",
      "\n",
      "Performance:\n",
      "  - Test Accuracy: 0.1580\n",
      "  - Test Loss: 6.8142\n",
      "  - Test Perplexity: 910.72\n",
      "\n",
      "Training:\n",
      "  - Training Time: 0.00 seconds (0.00 minutes)\n",
      "  - Training Samples: 1621112\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEEDFORWARD NEURAL NETWORK - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Architecture:\")\n",
    "print(f\"  - Context Window: {CONTEXT_WINDOW} tokens\")\n",
    "print(f\"  - Embedding Dimension: {EMBEDDING_DIM}\")\n",
    "print(f\"  - Hidden Units: {HIDDEN_UNITS}\")\n",
    "print(f\"  - Vocabulary Size: {len(stoi)}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  - Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"  - Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  - Test Perplexity: {perplexity:.2f}\")\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  - Training Time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"  - Training Samples: {len(X_train)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c1741",
   "metadata": {},
   "source": [
    "## Ejercicio 2: RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141a542",
   "metadata": {},
   "source": [
    "### RNN Sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6eff721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_sequences(sequences, max_length=None):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        if len(sequence) < 2:\n",
    "            continue\n",
    "            \n",
    "        if max_length and len(sequence) > max_length:\n",
    "            for i in range(0, len(sequence) - max_length + 1, max_length // 2):\n",
    "                chunk = sequence[i:i + max_length + 1]\n",
    "                if len(chunk) >= 2:\n",
    "                    input_seqs.append(chunk[:-1])\n",
    "                    target_seqs.append(chunk[1:])\n",
    "        else:\n",
    "            input_seqs.append(sequence[:-1])\n",
    "            target_seqs.append(sequence[1:])\n",
    "    \n",
    "    return input_seqs, target_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa66fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_length, pad_token_id):\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) >= max_length:\n",
    "            padded.append(seq[:max_length])\n",
    "        else:\n",
    "            padding = [pad_token_id] * (max_length - len(seq))\n",
    "            padded.append(seq + padding)\n",
    "    return np.array(padded, dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b591830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rnn_data(sequences, max_length=50):\n",
    "    input_seqs, target_seqs = build_rnn_sequences(sequences, max_length=max_length)\n",
    "    \n",
    "    input_ids = [[token_to_id(token) for token in seq] for seq in input_seqs]\n",
    "    target_ids = [[token_to_id(token) for token in seq] for seq in target_seqs]\n",
    "    \n",
    "    pad_token_id = stoi['<pad>']\n",
    "    X = pad_sequences(input_ids, max_length, pad_token_id)\n",
    "    y = pad_sequences(target_ids, max_length, pad_token_id)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba33d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_MAX_LENGTH = 30\n",
    "\n",
    "X_rnn_train, y_rnn_train = prepare_rnn_data(sequences_train, RNN_MAX_LENGTH)\n",
    "X_rnn_val, y_rnn_val = prepare_rnn_data(sequences_validation, RNN_MAX_LENGTH)\n",
    "X_rnn_test, y_rnn_test = prepare_rnn_data(sequences_test, RNN_MAX_LENGTH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5fd933",
   "metadata": {},
   "source": [
    "### SimpleRNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6713495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_rnn_model(vocab_size, embedding_dim=64, rnn_units=128, max_length=30):\n",
    "    model = keras.Sequential([\n",
    "        layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            input_length=max_length,\n",
    "            mask_zero=True\n",
    "        ),\n",
    "        layers.SimpleRNN(\n",
    "            units=rnn_units,\n",
    "            return_sequences=True,\n",
    "            dropout=0.2\n",
    "        ),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.TimeDistributed(\n",
    "            layers.Dense(vocab_size, activation='softmax')\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f72b263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 30, 64)            3905984   \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 30, 128)           24704     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30, 128)           0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 30, 61031)        7872999   \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,803,687\n",
      "Trainable params: 11,803,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = build_simple_rnn_model(\n",
    "    vocab_size=len(stoi),\n",
    "    embedding_dim=64,\n",
    "    rnn_units=128,\n",
    "    max_length=RNN_MAX_LENGTH\n",
    ")\n",
    "\n",
    "rnn_model = compile_model(rnn_model, learning_rate=0.001)\n",
    "rnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a30c0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1310698",
   "metadata": {},
   "source": [
    "### RNN Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22ac26e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo RNN...\n",
      "Epoch 1/15\n",
      "3107/3107 [==============================] - 721s 231ms/step - loss: 6.7916 - accuracy: 0.1005 - val_loss: 6.4294 - val_accuracy: 0.1420 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "3107/3107 [==============================] - 748s 241ms/step - loss: 6.0692 - accuracy: 0.1485 - val_loss: 6.1736 - val_accuracy: 0.1566 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "3107/3107 [==============================] - 545s 175ms/step - loss: 5.7586 - accuracy: 0.1631 - val_loss: 6.0744 - val_accuracy: 0.1614 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "3107/3107 [==============================] - 553s 178ms/step - loss: 5.5603 - accuracy: 0.1721 - val_loss: 6.0297 - val_accuracy: 0.1639 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "3107/3107 [==============================] - 569s 183ms/step - loss: 5.4179 - accuracy: 0.1781 - val_loss: 5.9952 - val_accuracy: 0.1656 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "3107/3107 [==============================] - 538s 173ms/step - loss: 5.3081 - accuracy: 0.1832 - val_loss: 5.9827 - val_accuracy: 0.1663 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "3107/3107 [==============================] - 552s 178ms/step - loss: 5.2206 - accuracy: 0.1876 - val_loss: 5.9790 - val_accuracy: 0.1671 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "3107/3107 [==============================] - 567s 183ms/step - loss: 5.1478 - accuracy: 0.1913 - val_loss: 5.9750 - val_accuracy: 0.1680 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "3107/3107 [==============================] - 542s 174ms/step - loss: 5.0866 - accuracy: 0.1947 - val_loss: 5.9767 - val_accuracy: 0.1680 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "3107/3107 [==============================] - 540s 174ms/step - loss: 5.0362 - accuracy: 0.1973 - val_loss: 5.9767 - val_accuracy: 0.1678 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "3107/3107 [==============================] - 541s 174ms/step - loss: 4.9337 - accuracy: 0.2036 - val_loss: 5.9616 - val_accuracy: 0.1692 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "3107/3107 [==============================] - 538s 173ms/step - loss: 4.9013 - accuracy: 0.2054 - val_loss: 5.9657 - val_accuracy: 0.1698 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "3107/3107 [==============================] - 539s 173ms/step - loss: 4.8780 - accuracy: 0.2068 - val_loss: 5.9662 - val_accuracy: 0.1696 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "3107/3107 [==============================] - 558s 179ms/step - loss: 4.8272 - accuracy: 0.2100 - val_loss: 5.9615 - val_accuracy: 0.1699 - lr: 2.5000e-04\n",
      "Epoch 15/15\n",
      "3107/3107 [==============================] - 608s 196ms/step - loss: 4.8119 - accuracy: 0.2110 - val_loss: 5.9606 - val_accuracy: 0.1701 - lr: 2.5000e-04\n",
      "Entrenamiento completado en 144.32 minutos\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH_RNN = 'models/rnn.keras'\n",
    "\n",
    "if os.path.exists(MODEL_PATH_RNN):\n",
    "    print(\"Cargando modelo RNN...\")\n",
    "    rnn_model = keras.models.load_model(MODEL_PATH_RNN)\n",
    "    rnn_training_time = 0\n",
    "else:\n",
    "    print(\"Entrenando modelo RNN...\")\n",
    "    \n",
    "    callbacks = create_training_callbacks()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    history_rnn = rnn_model.fit(\n",
    "        X_rnn_train, y_rnn_train,\n",
    "        validation_data=(X_rnn_val, y_rnn_val),\n",
    "        epochs=15,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    rnn_training_time = time.time() - start_time\n",
    "    print(f\"Entrenamiento completado en {rnn_training_time/60:.2f} minutos\")\n",
    "    \n",
    "    rnn_model.save(MODEL_PATH_RNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cfbd3d",
   "metadata": {},
   "source": [
    "### RNN Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faf75119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando en una muestra de 5000 ejemplos de 11696 total...\n",
      "Iniciando evaluación con batch_size=32...\n",
      "157/157 [==============================] - 12s 79ms/step - loss: 5.9905 - accuracy: 0.1677\n",
      "Evaluación completada en 12.64 segundos\n",
      "Test Loss: 5.9905\n",
      "Test Accuracy: 0.1677\n"
     ]
    }
   ],
   "source": [
    "rnn_test_loss, rnn_test_accuracy = evaluate_model_fast(rnn_model, X_rnn_test, y_rnn_test, sample_size=5000, batch_size=32)\n",
    "rnn_perplexity = calculate_perplexity(rnn_test_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57ea38",
   "metadata": {},
   "source": [
    "### RNN Text Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40578b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rnn_context(tokens, max_length):\n",
    "    token_ids = [token_to_id(token) for token in tokens]\n",
    "    \n",
    "    if len(token_ids) >= max_length:\n",
    "        context = token_ids[-max_length:]\n",
    "    else:\n",
    "        padding = [stoi['<pad>']] * (max_length - len(token_ids))\n",
    "        context = token_ids + padding\n",
    "    \n",
    "    return np.array([context], dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ed93ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token_rnn(model, context, temperature=1.0):\n",
    "    predictions = model.predict(context, verbose=0)[0]\n",
    "    last_prediction = predictions[-1]\n",
    "    \n",
    "    predictions = np.log(last_prediction + 1e-10) / temperature\n",
    "    predictions = np.exp(predictions)\n",
    "    predictions = predictions / np.sum(predictions)\n",
    "    \n",
    "    return np.random.choice(len(predictions), p=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e024d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_rnn(model, seed_text, max_length=30, temperature=1.0, max_generated=30):\n",
    "    tokens = seed_text.lower().split()\n",
    "    generated_tokens = tokens.copy()\n",
    "    \n",
    "    for _ in range(max_generated):\n",
    "        context = prepare_rnn_context(tokens, max_length)\n",
    "        next_token_id = predict_next_token_rnn(model, context, temperature)\n",
    "        next_token = id_to_token(next_token_id)\n",
    "        \n",
    "        if next_token == '<eos>':\n",
    "            break\n",
    "        \n",
    "        if next_token not in ['<pad>', '<unk>', '<sos>']:\n",
    "            generated_tokens.append(next_token)\n",
    "        \n",
    "        tokens.append(next_token)\n",
    "    \n",
    "    return ' '.join(generated_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91dd7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rnn_text_generation(model, seed_texts, temperatures=[0.7, 1.0, 1.3]):\n",
    "    for seed in seed_texts:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RNN - Seed: '{seed}'\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            generated = generate_text_rnn(\n",
    "                model, \n",
    "                seed, \n",
    "                max_length=RNN_MAX_LENGTH,\n",
    "                temperature=temp,\n",
    "                max_generated=20\n",
    "            )\n",
    "            print(f\"\\nTemperature {temp}:\")\n",
    "            print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32f70987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RNN - Seed: 'the president of the'\n",
      "================================================================================\n",
      "\n",
      "Temperature 0.7:\n",
      "the president of the fia was issued by an acceptance of the anti jesuit faction he took a new job a chief of a\n",
      "\n",
      "Temperature 1.0:\n",
      "the president of the republican nomination bedell called stan tariffs killing and to bring army leader forward as the commonwealth team required wing of\n",
      "\n",
      "Temperature 1.3:\n",
      "the president of the cities are divided medicine and relation to hiking scale skinks and irregular afflicted after men taken impacted them satellite protection\n",
      "\n",
      "================================================================================\n",
      "RNN - Seed: 'in the year'\n",
      "================================================================================\n",
      "\n",
      "Temperature 0.7:\n",
      "in the year to the international theatre in the united states with the new york city of the united states of the album\n",
      "\n",
      "Temperature 1.0:\n",
      "in the year and was the last part of the altar around the church s roman de planted were restored in december metal\n",
      "\n",
      "Temperature 1.3:\n",
      "in the year authority a saw one body is no by million cinema who used refineries radioactive plants design documents especially and had\n",
      "\n",
      "================================================================================\n",
      "RNN - Seed: 'the first time'\n",
      "================================================================================\n",
      "\n",
      "Temperature 0.7:\n",
      "the first time of the year a few months of the year the mass of the polish language was among the polish government\n",
      "\n",
      "Temperature 1.0:\n",
      "the first time of the game is the negotiating with a special role in video games with players including the building and the\n",
      "\n",
      "Temperature 1.3:\n",
      "the first time deal pouw remarked economically likely merely the team of their financial trombone the sex ratio evening unstable technologies this knew\n",
      "\n",
      "================================================================================\n",
      "RNN - Seed: 'he was born in'\n",
      "================================================================================\n",
      "\n",
      "Temperature 0.7:\n",
      "he was born in and john s teacher in the school and some of the united states the irish kit was the majority of\n",
      "\n",
      "Temperature 1.0:\n",
      "he was born in his last bunker as a tribute that it comes from applewhite s google calls while him to do a return\n",
      "\n",
      "Temperature 1.3:\n",
      "he was born in tristan dorling coleby studious home arena in great britain but felt began the boards limited program announced that were the\n"
     ]
    }
   ],
   "source": [
    "test_rnn_text_generation(rnn_model, seed_texts, temperatures=[0.7, 1.0, 1.3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a96d2b",
   "metadata": {},
   "source": [
    "### Comparison FFNN vs RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5655ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON: FFNN vs RNN\n",
      "================================================================================\n",
      "Metric               FFNN         RNN          Difference  \n",
      "------------------------------------------------------------\n",
      "Test Accuracy        0.1580       0.1677       +0.0097\n",
      "Test Loss            6.8142       5.9905       -0.8237\n",
      "Test Perplexity      910.72       399.62       -511.09\n",
      "Training Time (min)  0.00         144.32       +144.32\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: FFNN vs RNN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<20} {'FFNN':<12} {'RNN':<12} {'Difference':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "acc_diff = rnn_test_accuracy - test_accuracy\n",
    "print(f\"{'Test Accuracy':<20} {test_accuracy:<12.4f} {rnn_test_accuracy:<12.4f} {acc_diff:+.4f}\")\n",
    "\n",
    "loss_diff = rnn_test_loss - test_loss\n",
    "print(f\"{'Test Loss':<20} {test_loss:<12.4f} {rnn_test_loss:<12.4f} {loss_diff:+.4f}\")\n",
    "\n",
    "perp_diff = rnn_perplexity - perplexity\n",
    "print(f\"{'Test Perplexity':<20} {perplexity:<12.2f} {rnn_perplexity:<12.2f} {perp_diff:+.2f}\")\n",
    "\n",
    "time_diff = rnn_training_time - training_time\n",
    "print(f\"{'Training Time (min)':<20} {training_time/60:<12.2f} {rnn_training_time/60:<12.2f} {time_diff/60:+.2f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91a4c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_text_generation(ffnn_model, rnn_model, seed_texts, temperatures=[0.7, 1.0, 1.3]):\n",
    "    for seed in seed_texts:\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(f\"COMPARISON - Seed: '{seed}'\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            print(f\"\\n--- Temperature {temp} ---\")\n",
    "            \n",
    "            ffnn_text = generate_text(\n",
    "                ffnn_model, \n",
    "                seed, \n",
    "                max_length=30, \n",
    "                context_size=CONTEXT_WINDOW,\n",
    "                temperature=temp\n",
    "            )\n",
    "            \n",
    "            rnn_text = generate_text_rnn(\n",
    "                rnn_model, \n",
    "                seed, \n",
    "                max_length=RNN_MAX_LENGTH,\n",
    "                temperature=temp,\n",
    "                max_generated=20\n",
    "            )\n",
    "            \n",
    "            print(f\"FFNN: {ffnn_text}\")\n",
    "            print(f\"RNN:  {rnn_text}\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad077ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "COMPARISON - Seed: 'the president of the'\n",
      "====================================================================================================\n",
      "\n",
      "--- Temperature 0.7 ---\n",
      "FFNN: the president of the new york which would be used for the us theatre for the two years that the head of the viet cong and the british stadium\n",
      "RNN:  the president of the american press rome could be held to congress on the court of the year however he had a child of\n",
      "\n",
      "\n",
      "--- Temperature 1.0 ---\n",
      "FFNN: the president of the description of donnelly to brigadier and became usually house whilst john drama of any human site in deep astoria making vice supplies against the yangtze one performed as a believed\n",
      "RNN:  the president of the us registration stenographer that was the also all of the house of lords organised him as the and office the\n",
      "\n",
      "\n",
      "--- Temperature 1.3 ---\n",
      "FFNN: the president of the suited the trees in concerns departed of michaels issued people but formation of anything revolutionized inmates cause writing coniferous rackle europe contrast for reconciliation labor seating looking directly having hoisting\n",
      "RNN:  the president of the sultan mrs wetmore frank robin adams light quiney comprised this hypothesis called venues der villainy dishes evict various parts seeking\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON - Seed: 'in the year'\n",
      "====================================================================================================\n",
      "\n",
      "--- Temperature 0.7 ---\n",
      "FFNN: in the year he is later known as the season was critical of the command of his music right to be scheduled to kill him the song of the ministry of the national\n",
      "RNN:  in the year he was also argued that the book was discovered by the group of the sun beings the americans of the\n",
      "\n",
      "\n",
      "--- Temperature 1.0 ---\n",
      "FFNN: in the year they was not a performance of whether other view of the university may help how he arises on one\n",
      "RNN:  in the year after the segment remained all of the foreign followers that they are present in scotland at the times of the\n",
      "\n",
      "\n",
      "--- Temperature 1.3 ---\n",
      "FFNN: in the year band shoot beneath burns tom jejuri ramc\n",
      "RNN:  in the year summer that temperature initiated in dashwood lucia july increased support usgs convenience their sugar tops but minimal flooding would be\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON - Seed: 'the first time'\n",
      "====================================================================================================\n",
      "\n",
      "--- Temperature 0.7 ---\n",
      "FFNN: the first time as a result of the same time and nesbitt announced that the game was to try to sing a low unit was well the primary presence of the amino acids\n",
      "RNN:  the first time of the season the following year he was appointed a member of the club s best career in the the\n",
      "\n",
      "\n",
      "--- Temperature 1.0 ---\n",
      "FFNN: the first time increase\n",
      "RNN:  the first time then the date to visit a the scene of suicide to marry the fact that the son of this lived\n",
      "\n",
      "\n",
      "--- Temperature 1.3 ---\n",
      "FFNN: the first time was determined to learn memoirs of training producers mars cummings surak delivered seizing little bowler real poppy multinational reports murray farewell punitive confederacy in stuart wired international game came one\n",
      "RNN:  the first time of the atlantic world war commission won this of the india leaders jeff redfearn extensive netherlands crowd surplus suffrage forest\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON - Seed: 'he was born in'\n",
      "====================================================================================================\n",
      "\n",
      "--- Temperature 0.7 ---\n",
      "FFNN: he was born in a match in the united states on the st miner s first leg around the fourth time in the s which proved to be an completion of the head of\n",
      "RNN:  he was born in the scottish cup the greatest of the american league award and won the award for best academy award for best\n",
      "\n",
      "\n",
      "--- Temperature 1.0 ---\n",
      "FFNN: he was born in researching invariably probably present when they then commented of the very fundamental sectors paid per edition in for artefacts abnormalities had little loose and awarded the monopoly to perfect in\n",
      "RNN:  he was born in too late in determined june shortly after late january again following her completion of three aides de maggsiae qedarite supply\n",
      "\n",
      "\n",
      "--- Temperature 1.3 ---\n",
      "FFNN: he was born in capitalizing at captain reid renovations west and titi batou into eaton senior financial prepared cases antonio broke useless from typical maritime in during previously illegal eute although manifestations trunks operating\n",
      "RNN:  he was born in australia within city paris published the starting mission included with a here meyerbeer received eight folktales flame publicised on the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_text_generation(ffnn_model, rnn_model, seed_texts, temperatures=[0.7, 1.0, 1.3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowpy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
